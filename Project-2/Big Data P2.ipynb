{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Simulating an EKG by application \n",
    "## of the concept of Fourier Series\n",
    "## http://en.wikipedia.org/wiki/Fourier_series\n",
    "\n",
    "from numpy import sin\n",
    "\n",
    "x = np.linspace(0,100,1000)\n",
    "\n",
    "### consitituent waves ###\n",
    "# might I suggest: if you want to turn off one of the sine waves,\n",
    "# just set its a variable to 0\n",
    "\n",
    "#this one is big and sets the overall waveform\n",
    "a3=10\n",
    "f3 = .5\n",
    "y3 =  a3*sin(f3*x)\n",
    "#second biggest wave\n",
    "a2 = 5\n",
    "f2 = 2\n",
    "y2 = a2*sin(f2*x)\n",
    "#this one didn't seem useful, so I ditched it using the a=0 technique\n",
    "a1=0 #1\n",
    "f1=7\n",
    "y1 = a1*sin(f1*x)\n",
    "#this one adds periodic noise.\n",
    "a4 = .5\n",
    "f4 = 20\n",
    "y4 =a4*sin(f4*x) \n",
    "\n",
    "#random noise\n",
    "n = len(x)\n",
    "random_noise = np.random.rand(n)*np.random.randint(0,10,n)\n",
    "\n",
    "# ekg signal\n",
    "EKG = y1+y2+y3+y4+random_noise\n",
    "\n",
    "#plot the complete â€˜EKG'\n",
    "plt.plot(x, EKG,'b',lw=3)\n",
    "\n",
    "#plot the component waves\n",
    "plt.plot(x, y4, 'm')\n",
    "plt.plot(x, y3, 'r')\n",
    "plt.plot(x, y2, 'y')\n",
    "plt.plot(x, y1, 'g')\n",
    "plt.plot(x, random_noise, 'c')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Non-Bass Way to do peak detect\n",
    "####requires installation of pypeaks (https://github.com/gopalkoduri/pypeaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Elapsed time</th>\n",
       "      <th>iltered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(seconds)</th>\n",
       "      <th>(mV)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.502</th>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elapsed time iltered\n",
       "      (seconds)    (mV)\n",
       "0.500             0.040\n",
       "0.502             0.035"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pypeaks as pypk\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import os.path as path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "'''\n",
    "data = pickle.load(file(\"./sample-histogram.pickle\"))\n",
    "#print data\n",
    "hist = pypk.Data(data[0], data[1])\n",
    "'''\n",
    "#ji_intervals = pickle.load(file('./ji-intervals.pickle'))\n",
    "#print ji_intervals\n",
    "\n",
    "#pypk.Data.get_peaks??\n",
    "#pd.DataFrame.from_csv(path, header=0, sep=',', index_col=0, parse_dates=True, \n",
    "#                        encoding=None, tupleize_cols=False, infer_datetime_format=False)\n",
    "all_data = pd.DataFrame.from_csv('p01_r01_f_2.txt', header=[0,1], sep=\"\\t\")\n",
    "data = all_data[0.5:]\n",
    "\n",
    "#data.plot()\n",
    "#plt.show()\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Signature: hist.get_peaks(method='slope', peak_amp_thresh=5e-05, \n",
    "                          valley_thresh=3e-05, intervals=None, lookahead=20, avg_interval=100)\n",
    "Docstring:\n",
    "This function expects SMOOTHED histogram. If you run it on a raw histogram,\n",
    "there is a high chance that it returns no peaks.\n",
    "\n",
    "method can be interval/slope/hybrid.\n",
    "    The interval-based method simply steps through the whole histogram\n",
    "    and pick up the local maxima in each interval, from which irrelevant\n",
    "    peaks are filtered out by looking at the proportion of points on \n",
    "    either side of the detected peak in each interval, and by applying\n",
    "    peal_amp_thresh and valley_thresh bounds.\n",
    "\n",
    "    Slope approach uses, of course slope information, to find peaks, \n",
    "    which are then filtered by applying peal_amp_thresh and \n",
    "    valley_thresh bounds. \n",
    "    \n",
    "    Hybrid approach combines the peaks obtained using slope method and\n",
    "    interval-based approach. It retains the peaks/valleys from slope method\n",
    "    if there should be a peak around the same region from each of the methods.\n",
    "\n",
    "peak_amp_thresh is the minimum amplitude/height that a peak should have\n",
    "in a normalized smoothed histogram, to be qualified as a peak. \n",
    "valley_thresh is viceversa for valleys!\n",
    "\n",
    "If the method is interval/hybrid, then the intervals argument must be passed\n",
    "and it should be an instance of Intervals class.\n",
    "\n",
    "If the method is slope/hybrid, then the lookahead and avg_window\n",
    "arguments should be changed based on the application. \n",
    "They have some default values though.\n",
    "\n",
    "The method stores peaks in self.peaks in the following format:\n",
    "{\"peaks\":[[peak positions], [peak amplitudes]],\n",
    "\"valleys\": [[valley positions], [valley amplitudes]]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#things you can change\n",
    "smooth_amount = 9\n",
    "peak_amp_threshold = 3e-05\n",
    "valley_amp_threshold = -2e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Extract Peaks and Valleys from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Get peaks and valleys from data and make dataframes\n",
    "\n",
    "hist = pypk.Data(data.index, data.values, smoothness=smooth_amount)\n",
    "hist.get_peaks(method='slope', peak_amp_thresh=peak_amp_threshold, \n",
    "               valley_thresh=valley_amp_threshold)\n",
    "valleys, peaks = hist.peaks.items()\n",
    "\n",
    "def flatten_list_of_iterables(iterable_of_iterables):\n",
    "    \"\"\"\n",
    "    iterable_of_iterables is an iterable of single-value iterables\n",
    "    \n",
    "    some of the data is a list or array of single-value lists or arrays\n",
    "    this flattens them by iterating thru the iterable of arrays/lists \n",
    "    and append the first (and only) element from each into a new 1-D array.\n",
    "    \"\"\"\n",
    "    return np.array([iterable[0] for iterable in iterable_of_iterables])\n",
    "\n",
    "vx, vy = valleys[1]\n",
    "px, py = peaks[1]\n",
    "vy = flatten_list_of_iterables(vy)\n",
    "py = flatten_list_of_iterables(py)\n",
    "\n",
    "peaks_df = pd.DataFrame(data=zip(px,py), columns=[\"t\",\"A\"]).sort('t')\n",
    "valleys_df = pd.DataFrame(data=zip(vx,vy), columns=[\"t\",\"A\"]).sort('t')\n",
    "valleys_df.to_csv('valleys.csv')\n",
    "peaks_df.to_csv('peaks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot peaks and valleys over original data\n",
    "plt.plot(data.index, data.values)\n",
    "plt.plot(hist.x, hist.y)\n",
    "plt.plot(vx, vy, \"o\",c=\"tomato\")\n",
    "plt.plot(px, py, \"o\",c=\"orchid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>A</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.040</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552</td>\n",
       "      <td>0.055</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.644</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t      A type\n",
       "0  0.500  0.040    v\n",
       "1  0.552  0.055    p\n",
       "2  0.644 -0.010    v"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_event_time_to_amp(combined):\n",
    "    event_times = []\n",
    "    orig_amps = []\n",
    "    types = []\n",
    "    for k,df in combined.T.iteritems():\n",
    "\n",
    "        time = float(df['t'])\n",
    "        event_times.append(time)\n",
    "\n",
    "        amp = data.loc[time].values\n",
    "        orig_amps.append(amp)\n",
    "\n",
    "        feature_type = df['type']\n",
    "        types.append(feature_type)\n",
    "\n",
    "    amps = flatten_list_of_iterables(orig_amps)\n",
    "    temp_data = list(zip(event_times, amps, types))\n",
    "    index_list = range(len(event_times))\n",
    "    pv_orig_amps = pd.DataFrame(data = temp_data, index = index_list, \n",
    "                                columns=['t','A','type'])\n",
    "    return pv_orig_amps\n",
    "\n",
    "peaks_df['type'] = 'p'\n",
    "valleys_df['type'] = 'v'\n",
    "combined = pd.concat([peaks_df,valleys_df]).sort('t')\n",
    "orig_amps = map_event_time_to_amp(combined)\n",
    "orig_amps.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot peaks and valleys over original data\n",
    "plt.plot(data.index, data.values)\n",
    "plt.plot(orig_amps.t, orig_amps.A, \"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see the distribution of peaks\n",
    "# if the R peaks are much larger than the other peaks,\n",
    "# you can use calc_R_peak_lower_thresh to find the\n",
    "# lower bound of the R peaks\n",
    "# otherwise you may need to set \n",
    "# the variable R_peak_lower_bound (in the cell below) yourself.\n",
    "groupby_type = orig_amps.groupby('type')\n",
    "p = groupby_type.get_group('p')\n",
    "plt.hist(p['A'].values,2)\n",
    "plt.hist(p['A'].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "# separate peaks from valleys\n",
    "groupby_type = orig_amps.groupby('type')\n",
    "p, v = [groupby_type.get_group(i) for i in groupby_type.groups]\n",
    "\n",
    "def calc_R_peak_lower_thresh(peak_amplitudes):\n",
    "    #now find R features using the np.histogram\n",
    "    two_bin =  np.histogram(peak_amplitudes, 2)\n",
    "    bin_edges = two_bin[1]\n",
    "    mid = bin_edges[1]\n",
    "    return mid\n",
    "\n",
    "# you may need to set this yourself.\n",
    "R_peak_lower_bound = calc_R_peak_lower_thresh(p['A'])\n",
    "\n",
    "# separate out the R peaks, \n",
    "# all other peaks goes in other_peaks\n",
    "# some are T peaks, some are noise\n",
    "R_peaks = copy.deepcopy(p[p['A'] >= R_peak_lower_bound])\n",
    "other_peaks = copy.deepcopy(p[p['A'] <= R_peak_lower_bound])\n",
    "all_valleys = copy.deepcopy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check that R peaks were properly id'ed \n",
    "# (circles marking R peaks should now be different color from other peaks)\n",
    "plt.plot(data.index, data.values, 'r', c='deepskyblue')\n",
    "plt.plot(orig_amps.t, orig_amps.A, \"o\", c='cadetblue')\n",
    "plt.plot(R_peaks.t, R_peaks.A, \"o\",c='teal')\n",
    "plt.plot(all_valleys.t, all_valleys.A, \"o\",c='royalblue')\n",
    "plt.plot(other_peaks.t, other_peaks.A, \"o\", c=\"turquoise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>A</th>\n",
       "      <th>type</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.040</td>\n",
       "      <td>v</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552</td>\n",
       "      <td>0.055</td>\n",
       "      <td>p</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.644</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>v</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.646</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>v</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.702</td>\n",
       "      <td>0.620</td>\n",
       "      <td>p</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t      A type feature\n",
       "0  0.500  0.040    v        \n",
       "1  0.552  0.055    p        \n",
       "2  0.644 -0.010    v        \n",
       "3  0.646 -0.010    v        \n",
       "4  0.702  0.620    p       R"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label R peaks\n",
    "R_peaks.loc[:,'feature'] = 'R'\n",
    "\n",
    "recombined = pd.concat([R_peaks, other_peaks, all_valleys]).fillna('')\n",
    "sort_by_time = recombined.sort(\"t\")\n",
    "sort_by_time_T = sort_by_time.T\n",
    "\n",
    "sort_by_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.012,\n",
       " 1.758,\n",
       " 2.569,\n",
       " 3.5119999999999996,\n",
       " 4.4370000000000003,\n",
       " 5.3669999999999991,\n",
       " 6.2799999999999994,\n",
       " 7.1910000000000007,\n",
       " 8.0510000000000002,\n",
       " 8.9000000000000021,\n",
       " 9.7319999999999993,\n",
       " 10.546000000000001,\n",
       " 11.310000000000002,\n",
       " 12.035,\n",
       " 12.760000000000002,\n",
       " 13.510999999999999,\n",
       " 14.227,\n",
       " 15.004999999999999,\n",
       " 15.773999999999999,\n",
       " 16.585000000000001,\n",
       " 17.396999999999998,\n",
       " 18.260000000000002,\n",
       " 19.106999999999999,\n",
       " 19.966999999999999]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(index=sort_by_time.index)\n",
    "T_ends = []\n",
    "vs = []\n",
    "QT_intervals = []\n",
    "skipped = []\n",
    "for i in R_peaks.t.index:\n",
    "    \n",
    "    #print sort_by_time.loc[i-1:i+4]#, sort_by_time.loc[i+3]\n",
    "    \n",
    "    #try to locate the Q feature for this complex\n",
    "    #if not found, skip this complex\n",
    "    prev = sort_by_time.loc[i-1]\n",
    "    if prev['type'] == 'v' and prev['feature'] == \"\":\n",
    "        Qt = prev['t']\n",
    "    else:\n",
    "        skipped.append(i-1)\n",
    "        continue\n",
    "    \n",
    "    # starting at i+1 (one after the R peak)\n",
    "    # iterate until next peak (T feature) is found \n",
    "    while sort_by_time.loc[i+1]['type'] != 'p':\n",
    "        i += 1\n",
    "    T = sort_by_time.loc[i]['t']\n",
    "    \n",
    "    # starting one after i (b/c i is a peak)\n",
    "    # iterate until next valley is found\n",
    "    # optimally, this will be a valley \n",
    "    # immediately after T, but it doesn't matter that much\n",
    "    # unless that data has a linear trend\n",
    "    while sort_by_time.loc[i+1]['type'] != 'v':\n",
    "        i += 1\n",
    "    v = sort_by_time.loc[i]['t']\n",
    "    \n",
    "    if Q and v:\n",
    "        \n",
    "        T_end = v+ (v-T)/2\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    QT_intervals.append(T_end-Qt)\n",
    "    T_ends.append(T_end)\n",
    "    vs.append(v)\n",
    "        \n",
    "\n",
    "\n",
    "T_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check that R peaks were properly id'ed \n",
    "# (circles marking R peaks should now be different color from other peaks)\n",
    "plt.plot(data.index, data.values, 'r', c='deepskyblue')\n",
    "plt.plot(orig_amps.t, orig_amps.A, \"o\", c='cadetblue')\n",
    "plt.plot(R_peaks.t, R_peaks.A, \"o\",c='teal')\n",
    "plt.plot(all_valleys.t, all_valleys.A, \"o\",c='royalblue')\n",
    "plt.plot(other_peaks.t, other_peaks.A, \"o\", c=\"turquoise\")\n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.vlines(vs,ymin, ymax, color='orange')\n",
    "plt.vlines(T_ends,ymin, ymax, color='orchid')\n",
    "\n",
    "#plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Requires installation of PyBursts (https://github.com/rpoddighe/pybursts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>19.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   h  start     end\n",
       "0  0  0.002  19.996\n",
       "1  1  0.184   0.246\n",
       "2  2  0.244   0.246\n",
       "3  3  0.244   0.246\n",
       "4  4  0.244   0.246"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pybursts\n",
    "#this doesn't group entire QRST complex, but it does seem to get the QRS complex pretty well (h =1)\n",
    "\n",
    "bursts = pybursts.kleinberg(combined.t, s=2, gamma=.001)\n",
    "#print bursts\n",
    "#b = [i[1:] for i in bursts]\n",
    "bursts_df =  pd.DataFrame(data = bursts, index = range(len(bursts)), columns=['h','start','end'])\n",
    "print len(bursts_df)\n",
    "bursts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ymin, ymax = plt.ylim()\n",
    "maxh = max(bursts_df['h'])\n",
    "sorted_bursts = bursts_df.sort(\"h\")\n",
    "\"\"\"\n",
    "for r,c in zip(sorted_bursts.iterrows(),colors.cnames):#zip(bursts_df.start, bursts_df.end, colors.cnames):#bursts_df.iterrows():\n",
    "    #print r\n",
    "    h,s,e = r[1]\n",
    "    #print h\n",
    "    if h != 1:\n",
    "        continue\n",
    "    plt.vlines(s, ymin, ymax, color=c, lw=maxh-h)\n",
    "    plt.vlines(e, ymin, ymax, color=c, lw=maxh-h)\n",
    "    plt.hlines(ymin, s,e, color=c, lw=maxh-h)\n",
    "    plt.hlines(ymax, s, e, color=c, lw=maxh-h)\n",
    "    #break\"\"\"\n",
    "plt.plot(data.index, data.values,'y', label = \"original\")\n",
    "plt.plot(hist.x,hist.y, \"k\",label=\"smooth\", lw=2)\n",
    "plt.plot(vx, vy ,\"ro\", label=\"valleys\")\n",
    "plt.plot(px, py, \"co\", label=\"peaks\")\n",
    "\n",
    "plt.xlim(5,10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 4 92]\n",
      " [1.0 33 37]\n",
      " [1.0 76 92]\n",
      " [2.0 76 77]]\n"
     ]
    }
   ],
   "source": [
    "import pybursts\n",
    "\n",
    "offsets = [4, 17, 23, 27, 33, 35, 37, 76, 77, 82, 84, 88, 90, 92]\n",
    "print pybursts.kleinberg(offsets, s=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using BASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Peaks Amplitude  Intervals\n",
      "Time                             \n",
      "0.704            0.625      0.234\n",
      "0.938            0.175      0.516\n",
      "1.454            0.595      0.220\n",
      "1.674            0.175      0.594\n",
      "2.268            0.735      0.222\n",
      "Time\n",
      "0.704    0.625\n",
      "0.938    0.175\n",
      "1.454    0.595\n",
      "1.674    0.175\n",
      "2.268    0.735\n",
      "Name: Peaks Amplitude, dtype: float64\n",
      "0.175    4\n",
      "0.620    4\n",
      "0.210    3\n",
      "0.550    3\n",
      "0.165    3\n",
      "0.650    2\n",
      "0.195    2\n",
      "0.610    2\n",
      "0.575    1\n",
      "0.615    1\n",
      "0.690    1\n",
      "0.150    1\n",
      "0.285    1\n",
      "0.595    1\n",
      "0.495    1\n",
      "0.180    1\n",
      "0.490    1\n",
      "0.600    1\n",
      "0.160    1\n",
      "0.670    1\n",
      "0.245    1\n",
      "0.655    1\n",
      "0.215    1\n",
      "0.200    1\n",
      "0.795    1\n",
      "0.185    1\n",
      "0.480    1\n",
      "0.225    1\n",
      "0.325    1\n",
      "0.735    1\n",
      "0.190    1\n",
      "0.625    1\n",
      "dtype: int64\n",
      "[ 0.15    0.4725  0.795 ] [-0.235 -0.135 -0.035]\n"
     ]
    }
   ],
   "source": [
    "for key in ['Mean1']:\n",
    "    #represent what a complete feature looks like for this particular ECG\n",
    "    # s = burst start, e = burst end, v = valley, p=peak\n",
    "    features_key = 'vspevspe'\n",
    "    ''\n",
    "    \n",
    "    #count number of peaks and valleys in the features key\n",
    "    peak_count = features_key.count('p')\n",
    "    valley_count = features_key.count('v')\n",
    "\n",
    "    \n",
    "    peaks_df = Results['Peaks'][key].dropna() # R and T wave locations\n",
    "    valleys_df = Results['Valleys'][key].dropna() # Q and S wave locations\n",
    "    \n",
    "    # make bursts_df which contains 'Burst Start' vals and 'Burst End' vals\n",
    "    try:\n",
    "        burst_ends = Results['Bursts'][key]['Burst End']\n",
    "        burst_starts = Results['Bursts'][key]['Burst Start']\n",
    "        bursts_df = pd.concat([burst_starts, burst_ends], axis=1)\n",
    "        \n",
    "        bursts_df.columns = ['Start','End']\n",
    "    except:\n",
    "        print \"No bursts.\"\n",
    "        \n",
    "    #get peak and valley times\n",
    "    print (peaks_df.head())\n",
    "    peak_time = peaks_df.index.values\n",
    "    valley_time = valleys_df.index.values\n",
    "    \n",
    "print peaks_df[\"Peaks Amplitude\"].head()\n",
    "n, pEdges = np.histogram(peaks_df[\"Peaks Amplitude\"],bins=peak_count)\n",
    "n, vEdges = np.histogram(valleys_df,bins=valley_count)\n",
    "print pEdges, vEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Getting Q, R, S, and T in the DataFrame and Ordered according to Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you can see that Q, R, S, and T are being consistently detected (T should be marked by the burst ends) you can do the below process to label them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Mean1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-30ee97772687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpeaks_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Peaks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Mean1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# R wave location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvalleys_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Valleys'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Mean1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Q and S wave locations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mburst_ends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bursts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Mean1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Burst End'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#burst ends indicate approx. T wave location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# make new DataFrame for Burst Ends which is indexed by Burst Ends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Mean1'"
     ]
    }
   ],
   "source": [
    "peaks_df = Results['Peaks']['Mean1'] # R wave location\n",
    "valleys_df = Results['Valleys']['Mean1'] # Q and S wave locations\n",
    "burst_ends = Results['Bursts']['Mean1']['Burst End'] #burst ends indicate approx. T wave location\n",
    "\n",
    "# make new DataFrame for Burst Ends which is indexed by Burst Ends \n",
    "# b.c. Results['Bursts']['Mean1'] is indexed by Burst Start.\n",
    "bursts_df = pd.DataFrame(burst_ends.values, index=burst_ends.values, columns=['Burst Ends'])\n",
    "\n",
    "#combine peaks and valleys dfs and sort by time\n",
    "# this will allow us to easily find peaks, \n",
    "# and find valleys before and after.\n",
    "peaks_df['time'] = peaks_df.index\n",
    "valleys_df['time'] = valleys_df.index\n",
    "bursts_df['time'] = bursts_df.index\n",
    "peaks_df['amplitude'] = peaks_df[\"Peaks Amplitude\"]\n",
    "valleys_df['amplitude'] = valleys_df[\"Valley Amplitude\"]\n",
    "bursts_df['amplitude'] = float(Settings['Threshold'])\n",
    "\n",
    "#Label R and T. Unfortunatly, setting Q and S (the valleys) is much harder (See next cell).\n",
    "peaks_df['letter'] = 'R'\n",
    "bursts_df['letter'] = \"T\"\n",
    "\n",
    "combined = peaks_df.append(valleys_df).sort('time')\n",
    "\n",
    "#now combine w. Burst Ends and remove unnecessary columns, sort by time again\n",
    "times = combined.append(bursts_df).drop([u'Burst Ends', u'Intervals', u'Peaks Amplitude', u'Valley Amplitude'],axis=1)\n",
    "sorted_times = times.sort('time')\n",
    "#remove na vals only from amplitude col.\n",
    "sorted_times['amplitude'] = sorted_times['amplitude']\n",
    "sorted_times.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a hack-y way to set the Q and S valleys, but it works. Later I might try to do it with booleans. <b>Feel free to try another way to do this!!! (Actually, really, please do. This method is pretty slow.)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amplitude</th>\n",
       "      <th>letter</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.487</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.12950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.410</td>\n",
       "      <td>R</td>\n",
       "      <td>0.13475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.883</td>\n",
       "      <td>S</td>\n",
       "      <td>0.13825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030</td>\n",
       "      <td>T</td>\n",
       "      <td>0.15575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.455</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.30125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.514</td>\n",
       "      <td>R</td>\n",
       "      <td>0.30700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.934</td>\n",
       "      <td>S</td>\n",
       "      <td>0.31050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.030</td>\n",
       "      <td>T</td>\n",
       "      <td>0.32575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.376</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.47350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.404</td>\n",
       "      <td>R</td>\n",
       "      <td>0.47900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.003</td>\n",
       "      <td>S</td>\n",
       "      <td>0.48225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.030</td>\n",
       "      <td>T</td>\n",
       "      <td>0.49500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.59850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     amplitude letter     time\n",
       "num                           \n",
       "0       -0.487      Q  0.12950\n",
       "1        1.410      R  0.13475\n",
       "2       -0.883      S  0.13825\n",
       "3        0.030      T  0.15575\n",
       "4       -0.455      Q  0.30125\n",
       "5        1.514      R  0.30700\n",
       "6       -0.934      S  0.31050\n",
       "7        0.030      T  0.32575\n",
       "8       -0.376      Q  0.47350\n",
       "9        1.404      R  0.47900\n",
       "10      -1.003      S  0.48225\n",
       "11       0.030      T  0.49500\n",
       "12      -0.116    NaN  0.59850"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reindex by integer\n",
    "sorted_times['num'] = range(len(sorted_times))\n",
    "sorted_times_reindexed = sorted_times.set_index('num')\n",
    "\n",
    "letters = pd.DataFrame(index=sorted_times_reindexed.index, columns=['letters'], dtype=str)\n",
    "for i in sorted_times_reindexed.index:\n",
    "    \n",
    "    #try to get the previous and next values with error handeling for edge cases\n",
    "    try:\n",
    "        prev_value = sorted_times_reindexed.loc[i-1, \"letter\"]\n",
    "    except:\n",
    "        prev_value=''\n",
    "    try:\n",
    "        next_value = sorted_times_reindexed.loc[i+1,\"letter\"]\n",
    "    except:\n",
    "        next_value=\"\"\n",
    "    \n",
    "    #letters['time'][i] = sorted_times_reindexed.loc[i,'time']\n",
    "    if (next_value == \"T\") and (prev_value == \"R\"):\n",
    "        letters['letters'][i] = \"S\"\n",
    "    elif next_value == \"R\":\n",
    "        letters['letters'][i] = \"Q\"\n",
    "    else:\n",
    "        letters['letters'][i] = sorted_times_reindexed.loc[i,'letter']\n",
    "        \n",
    "sorted_times_reindexed['letter'] = letters['letters']\n",
    "sorted_times_reindexed.head(13) #see that valleys which are not immediately before or after R are left as NaN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amplitude</th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.12950</th>\n",
       "      <td>-0.487</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.13475</th>\n",
       "      <td>1.410</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.13825</th>\n",
       "      <td>-0.883</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15575</th>\n",
       "      <td>0.030</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30125</th>\n",
       "      <td>-0.455</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         amplitude letter\n",
       "time                     \n",
       "0.12950     -0.487      Q\n",
       "0.13475      1.410      R\n",
       "0.13825     -0.883      S\n",
       "0.15575      0.030      T\n",
       "0.30125     -0.455      Q"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_times_time_indexed = sorted_times_reindexed.set_index('time')\n",
    "final = sorted_times_time_indexed.dropna()\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1=0\n",
    "e1=20\n",
    "final[s1:e1].plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
