{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ECG Analysis for Detection of Long QT Syndrome 3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Introduction\n",
    "\n",
    "Long QT syndrome (LQTS) is a group of inherited arrhythmia caused by mutations in myocyte ion channels leading to delayed ventricular repolarization that can result in syncope and sudden death (Barsheshet et al., 2014; Chockalingam et al., 2015; Hofman et al., 2007; Modell and Lehmann, 2006; Priori et al., 2003; Roden, 2008). Several subtypes of LQTS have being identified, LQT 1 to LQT 10, each subtype containing a specific gene that is mutated(Modell and Lehmann, 2006; Roden, 2008), although each subtype can have several hundreds of different mutations causing that particular subtype(Chockalingam et al., 2015; Roden, 2008).  LQT1, LQT2, and LQT3 account for 95% of all LQTS subtypes(Barsheshet et al., 2014).  The prevalence of LQTS mutations is 1 in every 2,500 individuals, however heterozygous mutant carriers can be asymptomatic, it is estimated that 37% of LQTS carriers have normal QT intervals(Barsheshet et al., 2014; Roden, 2008). \n",
    "\n",
    "The QT interval has to be corrected for heart rate using Bazett's formula, QT interval divided by the square root of R-R interval, in order to determine if the QT is prolonged(Chockalingam et al., 2015; Hofman et al., 2007; Priori et al., 2003).  Diagnosis of long QT syndrome is very important because the first cardiac event can result in sudden death by ventricular fibrillation(Roden, 2008), the determination of what constitutes a long QT interval is age dependent, for 1-15 years old >460ms, for adult males, >450ms, and for adult females, >470ms(Barsheshet et al., 2014).  Different triggers can start the onset of cardiac events, physical stress, emotional stress, or even at rest syncope or sudden death can occur for LQTS patients(Modell and Lehmann, 2006; Priori et al., 2003; Roden, 2008).  Some LQTS subtypes have preferential triggers, in LQT1 62% of events happen after physical exercise especially swimming, in LQT2 emotional stress or an intense loud sound like an alarm clock triggered 43% of events, and in LQT3 39% of events happened at rest or while sleeping(Modell and Lehmann, 2006).  \n",
    "\n",
    "LQT1 has a mutation affecting KNCQ1 gene, that encodes for the alpha subunit of a voltage-gated potassium channel(Chockalingam et al., 2015; Modell and Lehmann, 2006; Roden, 2008).  The KNCQ1 controls the IKS, the slowly deactivating rectifying potassium current(Modell and Lehmann, 2006).  LQT2 subtype has a loss-of-function mutation in gene KCNH2. This gene encodes the alpha subunit of a potassium channel that is part of the IKR, the rapidly activating, rapidly deactivating delayed rectifier current(Chockalingam et al., 2015; Modell and Lehmann, 2006; Roden, 2008).  LQT3 does not have a mutation in a potassium channel, instead the affected gene, SCN5A, encodes a sodium channel in which a gain-of-function mutation leads reopening of sodium channels resulting in prolonged repolarization(Chockalingam et al., 2015; Modell and Lehmann, 2006; Roden, 2008).  \n",
    "\n",
    "ECG patterns can be characteristic for certain LQTS subtypes. For instance LQT1 has a broad base and early onset T-wave, LQT2 has a split or bifid T-wave or a low-amplitude T-wave, and LQT3 has a late onset T-wave and the ST segment might not return to P-wave baseline(Modell and Lehmann, 2006).  Even though genetic testing for mutations is the gold standard for diagnosing an individual with LQTS, ECG readings can provide an important clue to determine if someone is likely a carrier of a LQTS mutation.  In a study in which ECGs of relatives of known LQTS carriers where examined and then compared with genotyping results, it was concluded that a QT interval of 430ms or higher was a good cut off point to further DNA test these individuals(Hofman et al., 2007).  In order to better screen ECG readings we decided to automate the ECG reading process using python and R to see if we could determine a corrected QT interval in ECG database would belong to a possible carrier of LQTS mutation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SCN5A Sequence Analysis\n",
    "\n",
    "We decided to focus on mutations in the sodium channel [SCN5A](http://www.ncbi.nlm.nih.gov/gene/6331) gene which are responsible for LQTS3. First, we downloaded the [gene sequence](http://www.ncbi.nlm.nih.gov/nuccore/NC_000003.12?report=fasta&from=38548058&to=38649673&strand=true) into a FASTA file. Next, we searched [OMIM](http://www.omim.org/) for [SCN5A mutations](http://omim.org/allelicVariant/600163?sort=name) which are known to cause LQTS3. There were eleven relevant mutations, and they are as follows:\n",
    "- [NM_000335.4(SCN5A):c.5452G>A (p.Asp1818Asn)](http://www.ncbi.nlm.nih.gov/snp/137854619)\n",
    "- [NM_000335.4(SCN5A):c.4508_4516delAGAAGCCCC (p.Gln1506_Pro1508del)](http://www.ncbi.nlm.nih.gov/snp/397514251)\n",
    "- [NM_000335.4(SCN5A):c.4928G>A (p.Arg1643His)](http://www.ncbi.nlm.nih.gov/snp/28937316)\n",
    "- [NM_000335.4(SCN5A):c.3971A>G (p.Asn1324Ser)](http://www.ncbi.nlm.nih.gov/snp/28937317)\n",
    "- [NM_000335.4(SCN5A):c.4865G>A (p.Arg1622Gln)](http://www.ncbi.nlm.nih.gov/snp/137854600)\n",
    "- [NM_000335.4(SCN5A):c.5347G>A (p.Glu1783Lys)](http://www.ncbi.nlm.nih.gov/snp/137854601)\n",
    "- [NM_000335.4(SCN5A):c.5382_5384dupTGA (p.Tyr1794_Glu1795insAsp)](http://www.ncbi.nlm.nih.gov/snp/397514449)\n",
    "- [NM_001099404.1(SCN5A):c.2821_2822delTCinsAA (p.Ser941Asn)](http://www.ncbi.nlm.nih.gov/snp/137854605)\n",
    "- [NM_000335.4(SCN5A):c.2989G>T (p.Ala997Ser)](http://www.ncbi.nlm.nih.gov/snp/137854609)\n",
    "- [NM_000335.4(SCN5A):c.5474G>A (p.Arg1825His)](http://www.ncbi.nlm.nih.gov/snp/137854610)\n",
    "- [NM_000335.4(SCN5A):c.5381A>G (p.Tyr1794Cys)](http://www.ncbi.nlm.nih.gov/snp/137854614)\n",
    "\n",
    "With these mutations entered into another FASTA file, we used Biopython to align the reference and mutant sequences and visualize the mutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO, AlignIO\n",
    "from Bio.Align.Applications import ClustalwCommandline\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio.Graphics import GenomeDiagram\n",
    "from reportlab.lib import colors as rlc\n",
    "from reportlab.lib.units import cm\n",
    "\n",
    "#Make a variable point to where ClustalW2 is on your computer\n",
    "clustalw_exe = r\"C:\\Program Files (x86)\\ClustalW2\\clustalw2.exe\"\n",
    "\n",
    "#Make sure you are in the same directory as the sequence FASTA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in the SCN5A refrence sequence\n",
    "SCN5A_ref = SeqIO.read('SCN5A.fasta','fasta')\n",
    "SCN5A_ref.name = 'SCN5A_ref'\n",
    "\n",
    "#Read in the SCN5A sequence with 11 known LQTS3 mutations added in\n",
    "SCN5A_mut = SeqIO.read('SCN5A_mutants.fasta','fasta')\n",
    "SCN5A_mut.name = 'SCN5A_mut'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Put both reference and mutant sequences into a list\n",
    "SCN5A_all = [SCN5A_ref,SCN5A_mut]\n",
    "\n",
    "#Write the sequences to a single FASTA file, so ClustalW can align them\n",
    "SeqIO.write(SCN5A_all,'SCN5A_all.fasta','fasta');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Uncomment if you want to align with Clustal W2\n",
    "#THIS TAKES FOREVER TO RUN\n",
    "#The output .aln and .dnd files are in the IPython-Big-Data repository \n",
    "# https://github.com/drcgw/IPython-Big-Data\n",
    "'''\n",
    "#Align the ref and mutant sequences\n",
    "cline_Clustal = ClustalwCommandline(clustalw_exe,infile='SCN5A_all.fasta')\n",
    "stdout, sdterr = cline_Clustal()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in the alignment file\n",
    "SCN5A_aln = AlignIO.read('SCN5A_all.aln','clustal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_diff_locations(ref,compare):\n",
    "    \"\"\"\n",
    "    Takes 2 Biopython Seq objects of equal size (aligned).\n",
    "    Returns a list of locations at which base in compare sequence != base in ref sequence.\n",
    "    \"\"\"\n",
    "    if len(ref) != len(compare):\n",
    "        raise ValueError('Seqs are not the same length!')\n",
    "    \n",
    "    diff_locations = []\n",
    "    \n",
    "    for i in range(len(ref)):\n",
    "        if ref[i] != compare[i]:\n",
    "            diff_locations.append(i)\n",
    "        \n",
    "    return diff_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find differences between ref and mutant sequences\n",
    "SCN5A_diffs = get_diff_locations(SCN5A_aln[0].seq,SCN5A_aln[1].seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up track plotting diagram\n",
    "tracks = GenomeDiagram.Diagram('SCN5A Mutations')\n",
    "features = tracks.new_track(1,greytrack=False)\n",
    "feature_set = features.new_set()\n",
    "\n",
    "#Background green to show reference seq\n",
    "feature_set.add_feature(SeqFeature(FeatureLocation(0,(len(SCN5A_aln[0].seq)-1))),\n",
    "                       name = 'SCN5A Mutations Associated w/ LQTS3',\n",
    "                       label=True, label_angle=0, color=rlc.cadetblue);\n",
    "\n",
    "#Add blue to show mutations\n",
    "for i in range(len(SCN5A_diffs)):\n",
    "    feature = SeqFeature(FeatureLocation(SCN5A_diffs[i],SCN5A_diffs[i]))\n",
    "    feature_set.add_feature(feature, color=rlc.aqua)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Write the diagram to a png, then read it back in using matplotlib\n",
    "tracks.draw(format='linear', pagesize=(15*cm,10*cm), fragments=4,\n",
    "         start=0, end=(len(SCN5A_aln[0].seq)-1))\n",
    "tracks.write('SCN5A_tracks.png', 'png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='SCN5A_tracks.png'>\n",
    "**Figure 1: LQTS3 Mutations in the SCN5A Gene.** This diagram shows the SCN5A gene, broken up into 4 fragments proceeding from 5' at the upper left to 3' at the bottom right. There are 11 mutations indicated in blue, and they all appear to be toward the 3' end of the gene. In fact, the several mutations closest to the 3' end are tightly grouped within the same short region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Physionet ECG Data\n",
    "\n",
    "In order to analyze ECG data, we first needed to find some raw ECG data. This section of the notebook downloads the ECG data from the [Physionet ECG-ID Database](http://www.physionet.org/physiobank/database/ecgiddb/) in the form of tab-delimited `.txt` files with no header.\n",
    "\n",
    "The file titles follow this pattern: `Person_##rec_##.txt`\n",
    "\n",
    "The first colum of data is **time (s)**, and the second column of data is **ECG I filtered (mV)**.\n",
    "\n",
    "According to the database description, there are 310 records in total, made up of between 2 and 20 records from each of 90 individuals. Each record is 20 seconds long.\n",
    "\n",
    "In order for this section of the notebook to work, you must first install the [Physionet WFDB software](http://www.physionet.org/physiotools/wfdb.shtml) and be able to run a `%%bash` cell. Download the [RECORDS](http://www.physionet.org/physiobank/database/ecgiddb/RECORDS) file from Physionet, and put it in the same directory as this notebook.\n",
    "\n",
    "[Click here](https://drive.google.com/folderview?id=0BwnXy5kOXzB5fjJ3eVZUdVpqbmptVW1KSE8zUFlRM1dyTWp0ekFjdzZxMEk5OFZaYWg0ODg&usp=sharing) to see the results of this section of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the RECORDS file into a list\n",
    "records = open('RECORDS','r')\n",
    "rec_list = records.read()\n",
    "records.close()\n",
    "\n",
    "# Get rid of the last line, which\n",
    "# is an extra empty entry for some reason.\n",
    "rec_list = rec_list.split('\\n')\n",
    "del rec_list[-1]\n",
    "\n",
    "# Create a dict where the keys are the Person\n",
    "# and the values are a list of corresponding rec\n",
    "rec_dict = {}\n",
    "\n",
    "for i in range(len(rec_list)):\n",
    "    rec = rec_list[i].split('/')\n",
    "    if rec[0] in rec_dict:\n",
    "        rec_dict[rec[0]].append(rec[1])\n",
    "    else:\n",
    "        rec_dict[rec[0]] = []\n",
    "        rec_dict[rec[0]].append(rec[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a temporary file named Person##\n",
    "# where each line is a rec entry\n",
    "for k,v in rec_dict.iteritems():\n",
    "    p = open('people','a')\n",
    "    p.write(k+'\\n')\n",
    "    p.close()\n",
    "    f = open(k,'w')\n",
    "    for i in range(len(v)):\n",
    "        f.write(v[i]+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a `%%bash` cell to download Physionet files, and use Vim to delete the first 2 lines (headers) from each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in $(cat people); do\n",
    "    for ii in $(cat $i); do\n",
    "        rdsamp -r ecgiddb/$i/$ii -H -f 0 -t 20 -v -ps -s 'ECG I filtered' >$i$ii.txt\n",
    "        vi -c ':1,2d' -c ':wq' $i$ii.txt;\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove temporary files\n",
    "import os\n",
    "os.remove('people')\n",
    "for k in rec_dict.iterkeys():\n",
    "    os.remove(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##ECG Analysis\n",
    "\n",
    "The major tasks in analyzing the ECG for long-QT intervals are:\n",
    "<ol>\n",
    "   <li> Detecting peaks and valleys (data may require smoothing first) </li>\n",
    "   <li> Matching Q, R, S, and T to the detected peaks and valleys. </li>\n",
    "</ol>\n",
    "\n",
    "###Import modules, Load data\n",
    "For the next section, the pypeaks module is required and the seaborn module is strongly suggested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pypeaks as pypk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set_style(\"whitegrid\")\n",
    "except:\n",
    "    print (\"Consider installing Seaborn! \"\n",
    "           \"Its a great statistical plotting module \"\n",
    "           \"with pretty default settings to make your plots prettier!! \"\n",
    "           \"http://stanford.edu/~mwaskom/software/seaborn/\")\n",
    "\n",
    "file_name = '../p01_r01_f.txt'\n",
    "all_data = pd.DataFrame.from_csv(file_name, header=[0,1], sep=\"\\t\")\n",
    "\n",
    "# clip off first 1/2 second of data\n",
    "# this is probably optional\n",
    "# and will change for each data set\n",
    "data = all_data[0.5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Peak & Valley Detection\n",
    "\n",
    "Unfortunately, the method of peak detection causes some of the detected peaks and valleys to be time-offset from the actual peaks and valleys. The effect gets worse the more you smooth the signal, so there is a trade-off: a smoother signal is less likely to yield false-positives during event detection, but it is less accurate.\n",
    "\n",
    "####Settings you can change for peak detection\n",
    "\n",
    "smooth_amount: degree of smoothing done to data to prepare it for event detection\n",
    "\n",
    "peak_amp_thresh: the minimum amplitude/height that a peak should have in a normalized smoothed histogram, to be qualified as a peak. \n",
    "\n",
    "valley_thresh: the maximum amplitude/height that a valley should have in a normalized smoothed histogram, to be qualified as a valley. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth_amount = 4\n",
    "peak_amp_threshold = 3e-05\n",
    "valley_amp_threshold = 2e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get peaks and valleys from data \n",
    "# and make dataframes with columns \n",
    "# for time (t) and amplitude (A)\n",
    "\n",
    "hist = pypk.Data(data.index, data.values, smoothness=smooth_amount)\n",
    "hist.get_peaks(method='slope', peak_amp_thresh=peak_amp_threshold, \n",
    "               valley_thresh=valley_amp_threshold)\n",
    "valleys, peaks = hist.peaks.items()\n",
    "\n",
    "def flatten_list_of_iterables(iterable_of_iterables):\n",
    "    \"\"\"\n",
    "    iterable_of_iterables is an iterable of single-value iterables\n",
    "    \n",
    "    some of the data is a list or array of single-value lists or arrays\n",
    "    this flattens them by iterating thru the iterable of arrays/lists \n",
    "    and append the first (and only) element from each into a new 1-D array.\n",
    "    \"\"\"\n",
    "    return np.array([iterable[0] for iterable in iterable_of_iterables])\n",
    "\n",
    "vx, vy = valleys[1]\n",
    "px, py = peaks[1]\n",
    "vy = flatten_list_of_iterables(vy)\n",
    "py = flatten_list_of_iterables(py)\n",
    "\n",
    "peaks_df = pd.DataFrame(data=zip(px,py), columns=[\"t\",\"A\"]).sort('t')\n",
    "valleys_df = pd.DataFrame(data=zip(vx,vy), columns=[\"t\",\"A\"]).sort('t')\n",
    "#valleys_df.to_csv('valleys.csv')\n",
    "#peaks_df.to_csv('peaks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Peak detect returns peak and valley times and amplitudes \n",
    "# from smoothed data, but we want the original amplitudes\n",
    "# so we have to remap the times to the amplitudes\n",
    "def map_event_time_to_amp(combined):\n",
    "    event_times = []\n",
    "    orig_amps = []\n",
    "    types = []\n",
    "    for k,df in combined.T.iteritems():\n",
    "\n",
    "        time = float(df['t'])\n",
    "        event_times.append(time)\n",
    "\n",
    "        amp = data.loc[time].values\n",
    "        orig_amps.append(amp)\n",
    "\n",
    "        feature_type = df['type']\n",
    "        types.append(feature_type)\n",
    "\n",
    "    amps = flatten_list_of_iterables(orig_amps)\n",
    "    temp_data = list(zip(event_times, amps, types))\n",
    "    index_list = range(len(event_times))\n",
    "    pv_orig_amps = pd.DataFrame(data = temp_data, index = index_list, \n",
    "                                columns=['t','A','type'])\n",
    "    return pv_orig_amps\n",
    "\n",
    "peaks_df['type'] = 'p'\n",
    "valleys_df['type'] = 'v'\n",
    "\n",
    "combined = pd.concat([peaks_df,valleys_df]).sort('t')\n",
    "orig_amps = map_event_time_to_amp(combined)\n",
    "orig_amps.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Accuracy of Event Detection\n",
    "Determine if event detection settings need to be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## OPTIONAL\n",
    "# check accuracy of event detection\n",
    "\n",
    "# raw data\n",
    "plt.plot(data.index, data.values, 'r', c='deepskyblue', label=\"raw data\")\n",
    "# all the peaks and valleys\n",
    "plt.plot(orig_amps.t, orig_amps.A, \"o\", c='cadetblue', label=\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Locate the R-peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "# separate peaks from valleys\n",
    "groupby_type = orig_amps.groupby('type')\n",
    "p, v = [groupby_type.get_group(i) for i in groupby_type.groups]\n",
    "\n",
    "def calc_R_peak_lower_thresh(peak_amplitudes):\n",
    "    #now find R features using the np.histogram\n",
    "    two_bin =  np.histogram(peak_amplitudes, 2)\n",
    "    bin_edges = two_bin[1]\n",
    "    mid = bin_edges[1]\n",
    "    return mid\n",
    "\n",
    "# you may need to set this yourself.\n",
    "R_peak_lower_bound = calc_R_peak_lower_thresh(p['A'])\n",
    "\n",
    "# separate out the R peaks, \n",
    "# all other peaks goes in other_peaks\n",
    "# some are T peaks, some are noise\n",
    "R_peaks = copy.deepcopy(p[p['A'] >= R_peak_lower_bound])\n",
    "other_peaks = copy.deepcopy(p[p['A'] <= R_peak_lower_bound])\n",
    "all_valleys = copy.deepcopy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## OPTIONAL\n",
    "# check that R peaks were properly id'ed \n",
    "# (circles marking R peaks should now be different color from other peaks)\n",
    "\n",
    "# raw data\n",
    "plt.plot(data.index, data.values, 'r', c='deepskyblue', label=\"raw data\")\n",
    "# all the peaks and valleys (should be covered by the next set of plots)\n",
    "plt.plot(orig_amps.t, orig_amps.A, \"o\", c='cadetblue', label=\"\")\n",
    "# R-peaks, remaining peaks and all valleys\n",
    "plt.plot(R_peaks.t, R_peaks.A, \"o\",c='teal')\n",
    "plt.plot(all_valleys.t, all_valleys.A, \"o\",c='royalblue')\n",
    "plt.plot(other_peaks.t, other_peaks.A, \"o\", c=\"turquoise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#label R peaks\n",
    "R_peaks.loc[:,'feature'] = 'R'\n",
    "all_events = pd.concat([R_peaks, \n",
    "                        other_peaks, \n",
    "                        all_valleys]).fillna('').sort(\"t\")\n",
    "\n",
    "all_events.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Calc Q-T Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T_ends = []\n",
    "QT_intervals = []\n",
    "\n",
    "for i in R_peaks.t.index:\n",
    "        \n",
    "    #try to locate the Q feature for this complex\n",
    "    #if not found, skip this complex\n",
    "    prev = all_events.loc[i-1]\n",
    "    if prev['type'] == 'v' and prev['feature'] == \"\":\n",
    "        Qt = prev['t']\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "        # starting at i+1 (one after the R peak)\n",
    "    # iterate until next peak (T feature) is found\n",
    "    i += 1\n",
    "    while (all_events.loc[i]['type'] != 'p' \n",
    "           and all_events.loc[i]['feature'] != \"R\"):\n",
    "        i += 1\n",
    "    T = all_events.loc[i]['t']\n",
    "    #print \"T:\\n\",all_events.loc[i]\n",
    "    #print \n",
    "    \n",
    "    # starting one after i (b/c i is a peak)\n",
    "    # iterate until next valley is found\n",
    "    # optimally, this will be a valley \n",
    "    # immediately after T, but it doesn't matter that much\n",
    "    # unless that data has a linear trend\n",
    "    i += 1\n",
    "    while all_events.loc[i]['type'] != 'v':\n",
    "        i += 1\n",
    "    v = all_events.loc[i]['t']\n",
    "    #print \"v:\\n\",all_events.loc[i]\n",
    "    #print \n",
    "    try:\n",
    "        #print \"v, T: \", v, T\n",
    "        #print \"(v-T)/2: \",(v-T)/2\n",
    "        T_end = T + (v-T)/2\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    #print T, v, T_end\n",
    "\n",
    "        \n",
    "    QT_intervals.append(T_end-Qt)\n",
    "    T_ends.append(T_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## OPTIONAL\n",
    "# check that R peaks were properly id'ed \n",
    "# (circles marking R peaks should now be different color from other peaks)\n",
    "\n",
    "# raw data\n",
    "plt.plot(data.index, data.values, 'r', c='deepskyblue', label=\"raw data\")\n",
    "# R-peaks, remaining peaks and all valleys\n",
    "plt.plot(R_peaks.t, R_peaks.A, \"o\",c='teal', label=\"R\")\n",
    "plt.plot(all_valleys.t, all_valleys.A, \"o\",c='royalblue', label=\"Valleys\")\n",
    "plt.plot(other_peaks.t, other_peaks.A, \"o\", c=\"turquoise\", label=\"remaining peaks\")\n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "#plt.vlines(vs,ymin, ymax, color='orange')\n",
    "plt.vlines(T_ends,ymin, ymax, color='orchid', label=\"end T peak\")\n",
    "plt.xlim(5,10)\n",
    "print max(R_peaks['A'])\n",
    "plt.ylim(min(all_valleys[\"A\"])/.4, max(R_peaks['A'])*1.9)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min(all_valleys[\"A\"])/-.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(QT_intervals)\n",
    "plt.xlabel('QT length (s)')\n",
    "plt.ylabel(\"# events\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QT_stats = pd.Series(QT_intervals).describe()\n",
    "QT_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Discussion\n",
    "\n",
    "The inherent noisiness of the data, combined with the great variability in T wave presentation (i.e., inverted, biphasic, absent), presented significant obstacles to automation of peak and burst detection. Although we were unable to find a way to completely automate ECG analysis and QT measurement of a large dataset, our work will provide a starting point for future studies in this area.\n",
    "\n",
    "Unfortunately, the method of peak detection causes some of the detected peaks and valleys to be time-offset from the actual peaks and valleys.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##References\n",
    "\n",
    "Barsheshet, A., Dotsenko, O., and Goldenberg, I. (2014). Congenital long QT syndromes: prevalence, pathophysiology and management. Paediatr. Drugs 16, 447–456.\n",
    "\n",
    "Chockalingam, P., Mizusawa, Y., and Wilde, A.A. (2015). Channelopathies - emerging trends in the management of inherited arrhythmias. Indian Pacing Electrophysiol. J. 15, 43–54.\n",
    "\n",
    "Hofman, N., Wilde, A.A.M., Kääb, S., van Langen, I.M., Tanck, M.W.T., Mannens, M.M.A.M., Hinterseer, M., Beckmann, B.-M., and Tan, H.L. (2007). Diagnostic criteria for congenital long QT syndrome in the era of molecular genetics: do we need a scoring system? Eur. Heart J. 28, 575–580.\n",
    "\n",
    "Modell, S.M., and Lehmann, M.H. (2006). The long QT syndrome family of cardiac ion channelopathies: a HuGE review. Genet. Med. Off. J. Am. Coll. Med. Genet. 8, 143–155.\n",
    "\n",
    "Priori, S.G., Schwartz, P.J., Napolitano, C., Bloise, R., Ronchetti, E., Grillo, M., Vicentini, A., Spazzolini, C., Nastoli, J., Bottelli, G., et al. (2003). Risk Stratification in the Long-QT Syndrome. N. Engl. J. Med. 348, 1866–1874.\n",
    "\n",
    "Roden, D.M. (2008). Long-QT Syndrome. N. Engl. J. Med. 358, 169–176."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
